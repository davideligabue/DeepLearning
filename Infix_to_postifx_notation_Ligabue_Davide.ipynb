{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyUL-EqJ1ek0"
      },
      "source": [
        "## Project of the student Davide Ligabue, MATRICOLA: 0001191187\n",
        "Exam of Deep Learning of June 2025."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPFPtHankgU8"
      },
      "source": [
        "# Project Description:\n",
        "\n",
        "The purpose of this project is to implement a neural network that performs the translation of mathematical formulae from traditional **infix notation**—where the operator appears between two operands—to **postfix** (also known as Reverse Polish Notation), where the operator follows the operands.\n",
        "\n",
        "Infix notation is the most commonly used in human-readable mathematics (e.g., a + b), but it is inherently ambiguous without additional syntactic aids such as parentheses or operator precedence rules. This ambiguity arises because different parse trees can correspond to the same expression depending on how operations are grouped.\n",
        "\n",
        "In contrast, postfix notation eliminates the need for parentheses entirely. The order of operations is explicitly encoded by the position of the operators relative to the operands, making it more suitable for stack-based evaluation and easier to parse programmatically.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Consider the ambiguous infix expression:\n",
        "a + b * c\n",
        "\n",
        "This expression can be parsed in at least two different ways:\n",
        "\n",
        "Interpretation (Infix):\t(a + b) * c\t   \n",
        "Equivalent Postfix: ab+c*\n",
        "\n",
        "Interpretation (Infix):\ta + (b * c)\t          \n",
        "Equivalent Postfix: abc*+\n",
        "\n",
        "\n",
        "This project aims to learn such disambiguations and generate the correct postfix form from a given infix expression using a data-driven approach based on neural networks. To simplify the task and control the complexity of expressions, we restrict our dataset to formulae with a maximum syntactic depth of 3. This means that the abstract syntax trees representing these expressions will have at most three levels, ensuring that the neural network operates on a bounded and manageable set of possible structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_tRkF6n6smU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Model, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XgR4couXJY2",
        "outputId": "f37eee86-3697-4c09-80e2-d7faee598059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "# For saving and sharing the model's weights\n",
        "!pip install -U gdown\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMciu-3tXIbJ",
        "outputId": "b8743343-3ab4-4e4f-a1fb-2adef1971256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMqv9WU0h6sp"
      },
      "outputs": [],
      "source": [
        "WEIGHTS_DIR = \"/content/drive/MyDrive/ColabNotebooks/project_DL_2025/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFSHpEHjpa1x"
      },
      "source": [
        "We build formulae using 5 identifiers a,b,c,d,e and 4 binary operators +,-,*,/.\n",
        "For simplicity we do not take advantage of precedence or associativity rules for infix notation, and suppose that all binary operations as always fully parenthesizes: (e1 op e2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IINM81OK61pH"
      },
      "outputs": [],
      "source": [
        "# -------------------- Constants --------------------\n",
        "OPERATORS = ['+', '-', '*', '/']\n",
        "IDENTIFIERS = list('abcde')\n",
        "SPECIAL_TOKENS = ['PAD', 'SOS', 'EOS']\n",
        "SYMBOLS = ['(', ')', '+', '-', '*', '/']\n",
        "VOCAB = SPECIAL_TOKENS + SYMBOLS + IDENTIFIERS + ['JUNK'] #may use junk in autoregressive generation\n",
        "\n",
        "token_to_id = {tok: i for i, tok in enumerate(VOCAB)}\n",
        "id_to_token = {i: tok for tok, i in token_to_id.items()}\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "PAD_ID = token_to_id['PAD']\n",
        "EOS_ID = token_to_id['EOS']\n",
        "SOS_ID = token_to_id['SOS']\n",
        "\n",
        "MAX_DEPTH = 3\n",
        "MAX_LEN = 4*2**MAX_DEPTH -2 #enough to fit expressions at given depth (+ EOS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-fO911d6_FW"
      },
      "outputs": [],
      "source": [
        "# -------------------- Expression Generation --------------------\n",
        "def generate_infix_expression(max_depth):\n",
        "    if max_depth == 0:\n",
        "        return random.choice(IDENTIFIERS)\n",
        "    elif random.random() < 0.5:\n",
        "        return generate_infix_expression(max_depth - 1)\n",
        "    else:\n",
        "        left = generate_infix_expression(max_depth - 1)\n",
        "        right = generate_infix_expression(max_depth - 1)\n",
        "        op = random.choice(OPERATORS)\n",
        "        return f'({left} {op} {right})'\n",
        "\n",
        "def tokenize(expr):\n",
        "    return [c for c in expr if c in token_to_id]\n",
        "\n",
        "def infix_to_postfix(tokens):\n",
        "    precedence = {'+': 1, '-': 1, '*': 2, '/': 2}\n",
        "    output, stack = [], []\n",
        "    for token in tokens:\n",
        "        if token in IDENTIFIERS:\n",
        "            output.append(token)\n",
        "        elif token in OPERATORS:\n",
        "            while stack and stack[-1] in OPERATORS and precedence[stack[-1]] >= precedence[token]:\n",
        "                output.append(stack.pop())\n",
        "            stack.append(token)\n",
        "        elif token == '(':\n",
        "            stack.append(token)\n",
        "        elif token == ')':\n",
        "            while stack and stack[-1] != '(':\n",
        "                output.append(stack.pop())\n",
        "            stack.pop()\n",
        "    while stack:\n",
        "        output.append(stack.pop())\n",
        "    return output\n",
        "\n",
        "def encode(tokens, max_len=MAX_LEN):\n",
        "    ids = [token_to_id[t] for t in tokens] + [EOS_ID]\n",
        "    return ids + [PAD_ID] * (max_len - len(ids))\n",
        "\n",
        "def decode_sequence(token_ids, id_to_token, pad_token='PAD', eos_token='EOS'):\n",
        "    \"\"\"\n",
        "    Converts a list of token IDs into a readable string by decoding tokens.\n",
        "    Stops at the first EOS token if present, and ignores PAD tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    for token_id in token_ids:\n",
        "        token = id_to_token.get(token_id, '?')\n",
        "        if token == eos_token:\n",
        "            break\n",
        "        if token != pad_token:\n",
        "            tokens.append(token)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def generate_dataset(n,max_depth=MAX_DEPTH):\n",
        "    X, Y = [], []\n",
        "    for _ in range(n):\n",
        "        expr = generate_infix_expression(MAX_DEPTH)\n",
        "        #expr = expr_gen.generate(max_depth=max_dthep)\n",
        "        infix = tokenize(expr)\n",
        "        postfix = infix_to_postfix(infix)\n",
        "        X.append(encode(infix))\n",
        "        Y.append(encode(postfix))\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "#you might use the shift function for teacher-forcing\n",
        "def shift_right(seqs):\n",
        "    shifted = np.zeros_like(seqs)\n",
        "    shifted[:, 1:] = seqs[:, :-1]\n",
        "    shifted[:, 0] = SOS_ID\n",
        "    return shifted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DENVmP3Jq5Zf"
      },
      "source": [
        "Let us define a simple dataset, and inspect a few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdlonKn47dE7"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = generate_dataset(200000)\n",
        "decoder_input_train = shift_right(Y_train)\n",
        "\n",
        "# Dataset\n",
        "X_val, Y_val = generate_dataset(20000)\n",
        "decoder_input_val = shift_right(Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TogClrT6F2Th",
        "outputId": "15312351-a65f-4be3-9ce7-64311d1b609a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "192303\n",
            "infix :  ( ( c / c ) / a )\n",
            "posfix notation:  c c / a /\n",
            "teacher forcing :  SOS c c / a /\n"
          ]
        }
      ],
      "source": [
        "i =  np.random.randint(200000)\n",
        "print(i)\n",
        "print(\"infix : \",decode_sequence(X_train[i],id_to_token))\n",
        "print(\"posfix notation: \",decode_sequence(Y_train[i],id_to_token))\n",
        "print(\"teacher forcing : \", decode_sequence(decoder_input_train[i],id_to_token))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgqDkVaztBuv"
      },
      "source": [
        "# Constraints\n",
        "* You may use any architecture (decoder-only, encoder-decoder, or other).\n",
        "\n",
        "* The maximum number of parameters is 2 million.\n",
        "\n",
        "* Beam search is not allowed.\n",
        "\n",
        "* You may adapt the formula generator to your needs, but preserve its core logic—especially the frequency distribution of formulas by depth, as it may significantly influence model performance.\n",
        "\n",
        "* You may train your model using a pre-generated fixed dataset (e.g., an array) or directly use an on-the-fly generator.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDUjK4SGvT0s"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We shall evaluate a generated item y_pred using \"prefix accuracy\", the lenght of\n",
        "the initial prefix of y_pred matching the ground true y_true. This will be divided by the maximum length of y_true and y_pred (up to EOS), so that a perfect match has score 1.\n",
        "\n",
        "* It's more informative than exact match (which is often 0)\n",
        "\n",
        "* It’s tighter than edit distance: focuses on generation flow\n",
        "\n",
        "* Captures where the model starts to make errors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeqyasiYxCpU"
      },
      "outputs": [],
      "source": [
        "def prefix_accuracy_single(y_true, y_pred, id_to_token, eos_id=EOS_ID, verbose=False):\n",
        "    t_str = decode_sequence(y_true, id_to_token).split(' EOS')[0]\n",
        "    p_str = decode_sequence(y_pred, id_to_token).split(' EOS')[0]\n",
        "    t_tokens = t_str.strip().split()\n",
        "    p_tokens = p_str.strip().split()\n",
        "    max_len = max(len(t_tokens), len(p_tokens))\n",
        "\n",
        "    match_len = sum(x == y for x, y in zip(t_tokens, p_tokens))\n",
        "    score = match_len / max_len if max_len>0 else 0\n",
        "\n",
        "    if verbose:\n",
        "        print(\"TARGET :\", ' '.join(t_tokens))\n",
        "        print(\"PREDICT:\", ' '.join(p_tokens))\n",
        "        print(f\"PREFIX MATCH: {match_len}/{len(t_tokens)} → {score:.2f}\")\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeCRiqvsxQax"
      },
      "source": [
        "For the exam, evaluate you model on a test set of 20 expressions. Repeat this evaluation 10 times, and return the mean and std for this rounds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxxXPqKQ86fZ"
      },
      "source": [
        "Be sure to evalutate the generator: your model may only take as input the expression in infix format and return its translation to postifix.\n",
        "\n",
        "If you are usuing an encoder-decoder model, generation must be done autoregressively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj9E6PZd0Hoz"
      },
      "source": [
        "# Instructions\n",
        "If you don't want to retrain the model defined beloow you can download the pretrained weights using the cell under the paragraph **Load the weights**.\n",
        "\n",
        "You have to uncomment and run the cell which will download the weights using gdown and the they will be loaded in the model with the function `load_weight` of the class `Seq2Seq`.\n",
        "\n",
        "In this case be carefull to run all the notebook except for the paragraph Trining.\n",
        "\n",
        "Otherwise if you want to retrained all the model you can run the notebook without changing anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34MdVB86aUz-"
      },
      "source": [
        "# Project description\n",
        "\n",
        "For this project i decided to start implementing the simplest encoder-decoder architecture, where both the encoder and the decoder are implemented as Recurrent Neural Networks, in particular I decided to use the Long Short-Term Memory (LSTM) for this task.\n",
        "\n",
        "So below we can see the first two classes: `Encoder` and `Decoder` which define the encoder and the decoder respectively, and finally the class `Seq2Seq` which define our model.\n",
        "\n",
        "Later there is also the implementation of the function `autoregressive_decode` which produce the results, token by token, using the pre-defined (and trained) model in the given test function for the final model's evaluation\n",
        "\n",
        "\n",
        "In all my valutation I always keep the given parameters unchanged:\n",
        "\n",
        "\n",
        "*   `VOCAB_SIZE = len(VOCAB)`,\n",
        "*   `MAX_DEPTH = 3`,\n",
        "*   `MAX_LEN = 30`.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "I start running this first model using the following parameters:\n",
        "\n",
        "\n",
        "*   A train set of $100000$ samples,\n",
        "*   a validation set of $10000$ samples,\n",
        "* as hyperparameters:\n",
        "  * ` embedding_dim = 64`,\n",
        "  * `lstm_units = 128`,\n",
        "  * `batch_size = 256`.\n",
        "\n",
        "I obtained a fully appreciable result with a score of 1.0 and a standard deviation of 0.0.\n",
        "\n",
        "This result was reached after some tuning of the parameters (the last settings was reported above), and it's a strange result for a network, so logically I trained to explain my self this result thinking about the nature of this problem. It's a fully deterministic problem, where the network must learn some mathematical notions to be able to convert all the expressions, so rationally it's logical that a well-defined model reach the best score for this task.\n",
        "\n",
        "What I could implement now so was the number of trainable parameters of my model, which now is about $200,000$.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "The two main improvment i did was to define a new `loss_function`, based on the `SparseCategoricalCrossentropy`, which calculates the loss, masking out padding tokens, that are not relevant in our computation.\n",
        "\n",
        "Now I'm able to reduce the number of parameters in my model, but for a better training I decided to increase the size of the train and validation dataset.\n",
        "\n",
        "Here are the final and definitive parameters for my model:\n",
        "\n",
        "\n",
        "*   A train set of $200000$ samples,\n",
        "*   a validation set of $20000$ samples,\n",
        "* as hyperparameters:\n",
        "  * ` embedding_dim = 64`,\n",
        "  * `lstm_units = 64`,\n",
        "  * `batch_size = 256`.\n",
        "\n",
        "I trained this model over 50 epochs using two important callbacks:\n",
        "\n",
        "\n",
        "\n",
        "*   `ReduceLROnPlateau`,\n",
        "*   `EarlyStopping`.\n",
        "\n",
        "Now my model has a total number of trainable parameters of $68,943$ and it's still able to reach the perfect score:\n",
        "\n",
        "\n",
        "\n",
        "*   `score = 1.0`,\n",
        "*   `std = 0.0`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emauJCwdpqt4"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7caMDYX1_et"
      },
      "outputs": [],
      "source": [
        "class Encoder(Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, lstm_units):\n",
        "        super().__init__()\n",
        "        self.embedding = layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
        "        self.lstm = layers.LSTM(lstm_units, return_state=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embedded = self.embedding(inputs)\n",
        "        _, state_h, state_c = self.lstm(embedded)\n",
        "        return state_h, state_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGwd6vdn2BzO"
      },
      "outputs": [],
      "source": [
        "class Decoder(Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, lstm_units):\n",
        "        super().__init__()\n",
        "        self.embedding = layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
        "        self.lstm = layers.LSTM(lstm_units, return_sequences=True, return_state=True)\n",
        "        self.dense = layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, initial_state):\n",
        "        embedded = self.embedding(inputs)\n",
        "        output, state_h, state_c = self.lstm(embedded, initial_state=initial_state)\n",
        "        predictions = self.dense(output)\n",
        "        return predictions, state_h, state_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtlXnzX-2EI-"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(Model):\n",
        "    def __init__(self, encoder, decoder, weights_dir):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.weights_dir = weights_dir\n",
        "\n",
        "    def save_path(self, model_part):\n",
        "        os.makedirs(self.weights_dir, exist_ok=True)\n",
        "        return os.path.join(self.weights_dir, f\"{model_part}.weights.h5\")\n",
        "\n",
        "    def load_weight(self):\n",
        "        self.encoder.load_weights(self.save_path('encoder'))\n",
        "        self.decoder.load_weights(self.save_path('decoder'))\n",
        "        print(f\"Weights loaded from: {self.weights_dir}\")\n",
        "\n",
        "    def save_weight(self):\n",
        "        self.encoder.save_weights(self.save_path('encoder'))\n",
        "        self.decoder.save_weights(self.save_path('decoder'))\n",
        "        print(f\"Weights succesfully saved in: {self.weights_dir}\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        encoder_input, decoder_input = inputs\n",
        "        state_h, state_c = self.encoder(encoder_input)\n",
        "        predictions, _, _ = self.decoder(decoder_input, initial_state=[state_h, state_c])\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnErDV-h2KE8"
      },
      "outputs": [],
      "source": [
        "def autoregressive_decode(model, encoder_input_seq):\n",
        "    encoder_input_seq = tf.expand_dims(encoder_input_seq, 0)\n",
        "\n",
        "    encoder_h, encoder_c = model.encoder(encoder_input_seq)\n",
        "    decoder_states = [encoder_h, encoder_c]\n",
        "\n",
        "    # First token to decode -> SOS token\n",
        "    current_token_id = tf.constant([[SOS_ID]], dtype=tf.int32)\n",
        "\n",
        "    results = [SOS_ID]\n",
        "\n",
        "    for _ in range(MAX_LEN):\n",
        "        # Predict the next token\n",
        "        predictions, h, c = model.decoder(current_token_id, initial_state=decoder_states)\n",
        "        decoder_states = [h, c]\n",
        "\n",
        "        # Sample a token\n",
        "        predicted_token = tf.argmax(predictions[0, -1, :]).numpy()\n",
        "\n",
        "        results.append(predicted_token)\n",
        "\n",
        "        # If the model predicts EOS -> stop generation\n",
        "        if predicted_token == EOS_ID:\n",
        "            break\n",
        "\n",
        "        # Autoregressive approach -> input for the next prediction is the current predicted token\n",
        "        current_token_id = tf.constant([[predicted_token]], dtype=tf.int32)\n",
        "\n",
        "    return np.array(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWD_KXAu261d"
      },
      "outputs": [],
      "source": [
        "# Optimizer and Loss function\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, PAD_ID))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOmwEXG38oD0"
      },
      "outputs": [],
      "source": [
        "# Define the callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUnGL3wq2MyB"
      },
      "outputs": [],
      "source": [
        "# Model hyperparameters\n",
        "embedding_dim = 64\n",
        "lstm_units = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzTazOy0KnRg"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(VOCAB_SIZE, embedding_dim, lstm_units)\n",
        "decoder = Decoder(VOCAB_SIZE, embedding_dim, lstm_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jFyCLge2OPp"
      },
      "outputs": [],
      "source": [
        "model = Seq2Seq(encoder, decoder, WEIGHTS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT8YECEw2m7U"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "ERgzHpZ1714d",
        "outputId": "5b30c208-14b9-47f8-e95c-489592814120"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"seq2_seq_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"seq2_seq_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)             │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,984</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)             │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,959</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder_2 (\u001b[38;5;33mEncoder\u001b[0m)             │ ?                      │        \u001b[38;5;34m33,984\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_2 (\u001b[38;5;33mDecoder\u001b[0m)             │ ?                      │        \u001b[38;5;34m34,959\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,943</span> (269.31 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,943\u001b[0m (269.31 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,943</span> (269.31 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,943\u001b[0m (269.31 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Dummy initialization of the model\n",
        "dummy_encoder_input = tf.zeros((1, MAX_LEN), dtype=tf.int32)\n",
        "dummy_decoder_input = tf.zeros((1, MAX_LEN), dtype=tf.int32)\n",
        "\n",
        "_ = model((dummy_encoder_input, dummy_decoder_input))\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0XDKI1Bpw63"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2T5GUx42oZj",
        "outputId": "93d4c2c3-5294-4c26-fc45-ef2be4021a42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.2508 - val_loss: 0.0524 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0408 - val_loss: 0.0219 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0191 - val_loss: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.0067 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0064 - val_loss: 0.0050 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0034 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0017 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8710e-04 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 8.1742e-04 - val_loss: 6.6477e-04 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 6.2595e-04 - val_loss: 4.5808e-04 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 5.1215e-04 - val_loss: 5.7075e-04 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 4.4274e-04 - val_loss: 4.0690e-04 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 3.9108e-04 - val_loss: 2.8941e-04 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 3.6592e-04 - val_loss: 3.6266e-04 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 3.7533e-04 - val_loss: 1.1801e-04 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 1.5965e-04 - val_loss: 2.5963e-04 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.1893e-04 - val_loss: 1.1583e-04 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.3452e-04 - val_loss: 1.9501e-04 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 2.2083e-04 - val_loss: 1.4339e-04 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.4064e-05\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 9.4111e-05 - val_loss: 5.7641e-05 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 3.4402e-05 - val_loss: 3.4860e-05 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2933e-05 - val_loss: 2.7988e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 9.0881e-05 - val_loss: 2.4239e-05 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 7.5979e-05 - val_loss: 3.0197e-05 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m779/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1152e-05\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.1227e-05 - val_loss: 1.5257e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 3.1115e-05 - val_loss: 2.0346e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.3535e-05 - val_loss: 1.5988e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0527e-05 - val_loss: 1.4032e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 9.0631e-06 - val_loss: 1.2052e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 7.6573e-06 - val_loss: 1.4327e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 6.0068e-05 - val_loss: 1.2868e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.5556e-06\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 8.5550e-06 - val_loss: 1.0080e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 6.7873e-06 - val_loss: 9.3254e-06 - learning_rate: 1.2500e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 6.2332e-06 - val_loss: 8.8597e-06 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 5.5493e-06 - val_loss: 8.2200e-06 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 5.0797e-06 - val_loss: 8.8427e-06 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m777/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6580e-06\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 4.6580e-06 - val_loss: 7.4486e-06 - learning_rate: 1.2500e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 4.0167e-06 - val_loss: 6.4723e-06 - learning_rate: 6.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.7270e-06 - val_loss: 6.1226e-06 - learning_rate: 6.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 3.6176e-06 - val_loss: 5.8611e-06 - learning_rate: 6.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.2708e-06 - val_loss: 5.6898e-06 - learning_rate: 6.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m776/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.0636e-06\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.0635e-06 - val_loss: 5.8615e-06 - learning_rate: 6.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.7707e-06 - val_loss: 5.0971e-06 - learning_rate: 3.1250e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 2.6103e-06 - val_loss: 4.7318e-06 - learning_rate: 3.1250e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5470e-06 - val_loss: 4.7007e-06 - learning_rate: 3.1250e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 2.3714e-06 - val_loss: 4.4231e-06 - learning_rate: 3.1250e-05\n",
            "Restoring model weights from the end of the best epoch: 50.\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_train, decoder_input_train],\n",
        "    Y_train,\n",
        "    batch_size=256,\n",
        "    epochs=50,\n",
        "    validation_data=([X_val, decoder_input_val], Y_val),\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "jzdSep7k5aWf",
        "outputId": "545d280d-aa9b-4058-d4a2-35019cf19f6e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the training history\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ri6-VMhp0C3"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcepSzPMFop6"
      },
      "outputs": [],
      "source": [
        "def test(no=20,rounds=10):\n",
        "  rscores =[]\n",
        "  for i in range(rounds):\n",
        "    print(\"round=\",i)\n",
        "    X_test, Y_test = generate_dataset(no)\n",
        "    scores = []\n",
        "    for j in range(no):\n",
        "      encoder_input=X_test[j]\n",
        "      generated = autoregressive_decode(model, encoder_input)[1:] #remove SOS\n",
        "      scores.append(prefix_accuracy_single(Y_test[j], generated, id_to_token))\n",
        "    rscores.append(np.mean(scores))\n",
        "  return np.mean(rscores),np.std(rscores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2--VVn2a5tqV",
        "outputId": "14fe87bb-491c-4f8e-ada1-8f59dcdef069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round= 0\n",
            "round= 1\n",
            "round= 2\n",
            "round= 3\n",
            "round= 4\n",
            "round= 5\n",
            "round= 6\n",
            "round= 7\n",
            "round= 8\n",
            "round= 9\n",
            "score= 1.0 std= 0.0\n"
          ]
        }
      ],
      "source": [
        "# Test the model with the given test function\n",
        "res, std = test(20,10)\n",
        "print(\"score=\",res,\"std=\",std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0L6gwIYLr68",
        "outputId": "d9d15269-735f-4671-8f34-6e06b0de3117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Example Translations ---\n",
            "INFIX: ( ( b + a ) + ( d / c ) )\n",
            "TARGET : b a + d c / +\n",
            "PREDICT: b a + d c / +\n",
            "PREFIX MATCH: 7/7 → 1.00\n",
            "------------------------------\n",
            "INFIX: ( ( a * ( d / a ) ) + ( e * b ) )\n",
            "TARGET : a d a / * e b * +\n",
            "PREDICT: a d a / * e b * +\n",
            "PREFIX MATCH: 9/9 → 1.00\n",
            "------------------------------\n",
            "INFIX: ( e - ( ( d + c ) - c ) )\n",
            "TARGET : e d c + c - -\n",
            "PREDICT: e d c + c - -\n",
            "PREFIX MATCH: 7/7 → 1.00\n",
            "------------------------------\n",
            "INFIX: ( ( ( e + c ) * c ) - c )\n",
            "TARGET : e c + c * c -\n",
            "PREDICT: e c + c * c -\n",
            "PREFIX MATCH: 7/7 → 1.00\n",
            "------------------------------\n",
            "INFIX: ( ( a / e ) * ( c * e ) )\n",
            "TARGET : a e / c e * *\n",
            "PREDICT: a e / c e * *\n",
            "PREFIX MATCH: 7/7 → 1.00\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Example translations for verification\n",
        "print(\"\\n--- Example Translations ---\")\n",
        "for _ in range(5):\n",
        "    sample_infix_expr = generate_infix_expression(MAX_DEPTH)\n",
        "    sample_infix_tokens = tokenize(sample_infix_expr)\n",
        "    sample_postfix_tokens = infix_to_postfix(sample_infix_tokens)\n",
        "\n",
        "    encoded_infix = encode(sample_infix_tokens)\n",
        "    decoded_postfix_ids = autoregressive_decode(model, np.array(encoded_infix))[1:]\n",
        "\n",
        "    print(f\"INFIX: {decode_sequence(encoded_infix, id_to_token)}\")\n",
        "    _ = prefix_accuracy_single(encode(sample_postfix_tokens), decoded_postfix_ids, id_to_token, verbose=True)\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOj1hBsMXBQb",
        "outputId": "076d8a7e-0044-4cb8-ed39-814559f4f7c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights succesfully saved in: /content/drive/MyDrive/ColabNotebooks/project_DL_2025/\n"
          ]
        }
      ],
      "source": [
        "# Save the weights\n",
        "model.save_weight()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-sFkhUTmmfJ"
      },
      "source": [
        "# Load the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "-qwsJABWmlqq",
        "outputId": "4cc7552a-6aba-4775-d60c-a3acb1dfcffb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nWEIGHTS_DIR = \"/content/drive/MyDrive/ColabNotebooks/project_DL_2025/\"\\nos.makedirs(WEIGHTS_DIR, exist_ok=True)\\n\\nENCODER_PATH = os.path.join(WEIGHTS_DIR, \"encoder.weights.h5\")\\nDECODER_PATH = os.path.join(WEIGHTS_DIR, \"decoder.weights.h5\")\\n\\nif not os.path.exists(ENCODER_PATH):\\n    gdown.download(id=ENCODER_FILE_ID, output=ENCODER_PATH, quiet=False)\\n\\nif not os.path.exists(DECODER_PATH):\\n    gdown.download(id=DECODER_FILE_ID, output=DECODER_PATH, quiet=False)\\n\\n\\n# Load the weights\\nmodel.load_weights()\\n\\n'"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load pretrained weights instead of training\n",
        "ENCODER_FILE_ID = '1MQBlQfZaCjDql3MODs6glcXzc8sZS7lT'\n",
        "DECODER_FILE_ID = '1bOED86nHV7wHOmjNZMNkPgwk1hf_1Q8Q'\n",
        "\n",
        "'''\n",
        "WEIGHTS_DIR = \"/content/drive/MyDrive/ColabNotebooks/project_DL_2025/\"\n",
        "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
        "\n",
        "ENCODER_PATH = os.path.join(WEIGHTS_DIR, \"encoder.weights.h5\")\n",
        "DECODER_PATH = os.path.join(WEIGHTS_DIR, \"decoder.weights.h5\")\n",
        "\n",
        "if not os.path.exists(ENCODER_PATH):\n",
        "    gdown.download(id=ENCODER_FILE_ID, output=ENCODER_PATH, quiet=False)\n",
        "\n",
        "if not os.path.exists(DECODER_PATH):\n",
        "    gdown.download(id=DECODER_FILE_ID, output=DECODER_PATH, quiet=False)\n",
        "\n",
        "\n",
        "# Load the weights\n",
        "model.load_weight()\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOBottQI9o1h"
      },
      "source": [
        "# What to deliver\n",
        "\n",
        "As usual you are supposed to deliver a single notebook witten in Keras. You are auhtorized to use Keras3 with pytorch as backend if your prefer.\n",
        "\n",
        "Do no upload a zip file: the submission will be rejected.\n",
        "\n",
        "The python notebook should have a clear documentation of the training phase, possibly with its history.\n",
        "\n",
        "You should be able to provide the network paramters upon request. Even better, consider a way to upload them inside your notebook using gdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjpngkfcrQZC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "aOBottQI9o1h"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
